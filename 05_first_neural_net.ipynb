{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f0579dc-53c6-45dd-8fec-244f944df6a1",
   "metadata": {},
   "source": [
    "# First Neural Net\n",
    "Let's figure out how we would take our data and use it to train a neural net. We'll focus on figuring out how to tokenize the data and how it would be fed into and out of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b839778-f535-420e-93d7-b98e61eac234",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f9f4657-e5cb-4355-9d9a-5d0397109ade",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"cleaned_data/clean_2.csv\", keep_default_na=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543563a4-ea92-42c5-bbba-5096a9fdd1f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Vocabulary Building\n",
    "Let's use pytorch to build up a vocabulary. The default tokenizer is probably fine for now, but something we should consider changing in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71ee77e6-4192-4b3b-9ca1-b9595549eab2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "def yield_tokens(data_iter):\n",
    "    for text in data_iter:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "answers_vocab = build_vocab_from_iterator(yield_tokens(df['answer'].values), specials=[\"<unk>\"])\n",
    "clues_vocab = build_vocab_from_iterator(yield_tokens(df['clue'].values), specials=[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6229c55-5d07-42c2-9532-1f744538e1e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens in clues vocab: 84344\n",
      "Tokens in answers vocab: 62953\n"
     ]
    }
   ],
   "source": [
    "print('Tokens in clues vocab:', len(clues_vocab))\n",
    "print('Tokens in answers vocab:', len(answers_vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ebe410-cf15-4f34-9f31-74753bc65056",
   "metadata": {},
   "source": [
    "Add some helpers to make conversion from strings to tokens easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb119da3-e034-4e33-bec8-cfe3db10b038",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clue_pipeline = lambda x: clues_vocab(tokenizer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7fe91f1-4f83-4891-b127-6a3f2ed7ef9a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[112, 4, 3052]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clue_pipeline('capital of canada')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e796d22e-ec2f-485c-9e51-bd67bb7e790d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4411"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_vocab.get_stoi()['ottawa']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104492b3-1d35-4cfd-8f6f-3f85ebb5d43e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Setup\n",
    "Let's create tensors for our inputs and labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a9b475-750d-4bc1-8bd6-46a60a7636f4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Input and Output\n",
    "We want to input the clue and output the potential answer. Clues are encoded as a list of ints where each int ia a word in the clue vocabulary; answers are a single int which represents a word in the answer vocabulary.\n",
    "\n",
    "We can directly input the encoded clue, but we need to consider that clues are different lengths and we need a consistent shape for our inputs. We can solve for this by padding inputs to a fixed length.\n",
    "\n",
    "First, we must add a padding token to our vocabulary. Second, we need to figure out the length of the input which we can base off of the longest clue in the training set (note: this will fail if any clues in the test set are longer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83deb75a-07b1-4556-a860-a274046949b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "answers_vocab = build_vocab_from_iterator(yield_tokens(df['answer'].values), specials=[\"<pad>\"])\n",
    "clues_vocab = build_vocab_from_iterator(yield_tokens(df['clue'].values), specials=[\"<pad>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4d4d1d3-960a-4325-a182-882b96e8b70c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> <pad>\n"
     ]
    }
   ],
   "source": [
    "print(answers_vocab.get_itos()[0], clues_vocab.get_itos()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5083291-c18d-4e79-96e4-74b797270e34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PADDING_TOKEN_INDEX = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b291d037-7890-4e35-9498-0ddcd309cb5a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data Splits\n",
    "Let's create train, dev, and test splits of the data. We'll use a 80-10-10 breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eba7e442-c75d-435a-814f-c1b8fa6f4569",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 616288\n",
      "Dev set size: 77036\n",
      "Test set size: 77037\n"
     ]
    }
   ],
   "source": [
    "train, dev, test = np.split(df.sample(frac=1, random_state=42), [int(.8*len(df)), int(.9*len(df))])\n",
    "\n",
    "# Print the size of each subset\n",
    "print(f'Train set size: {len(train)}')\n",
    "print(f'Dev set size: {len(dev)}')\n",
    "print(f'Test set size: {len(test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13717a01-0d05-4513-922f-f8d769ed8a09",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer</th>\n",
       "      <th>clue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pat</td>\n",
       "      <td>action done while saying \"good dog\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rascals</td>\n",
       "      <td>mischief-makers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pen</td>\n",
       "      <td>it might click for a writer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eco</td>\n",
       "      <td>kind to mother nature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>wage</td>\n",
       "      <td>living ___</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770352</th>\n",
       "      <td>ars</td>\n",
       "      <td>\"___ magna\" (anagrams, appropriately)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770353</th>\n",
       "      <td>doze</td>\n",
       "      <td>nap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770356</th>\n",
       "      <td>nat</td>\n",
       "      <td>actor pendleton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770358</th>\n",
       "      <td>nea</td>\n",
       "      <td>teachers' org.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770360</th>\n",
       "      <td>sis</td>\n",
       "      <td>family girl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>616288 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         answer                                   clue\n",
       "0           pat    action done while saying \"good dog\"\n",
       "1       rascals                        mischief-makers\n",
       "2           pen            it might click for a writer\n",
       "4           eco                  kind to mother nature\n",
       "6          wage                             living ___\n",
       "...         ...                                    ...\n",
       "770352      ars  \"___ magna\" (anagrams, appropriately)\n",
       "770353     doze                                    nap\n",
       "770356      nat                        actor pendleton\n",
       "770358      nea                         teachers' org.\n",
       "770360      sis                            family girl\n",
       "\n",
       "[616288 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856ad1bf-c3fd-421d-828e-7169c0cd5b17",
   "metadata": {},
   "source": [
    "Let's figure out what the longest clue is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a21f902a-3e62-4f27-b24f-ce9a10381eff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['clue'].apply(lambda x: len(clue_pipeline(x))).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb05644d-a83a-451b-a66b-d74c7f410f36",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev['clue'].apply(lambda x: len(clue_pipeline(x))).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aefd0219-3874-4680-982e-20d12d079598",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['clue'].apply(lambda x: len(clue_pipeline(x))).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eba9294-9730-4925-9ed0-06bb187f627e",
   "metadata": {
    "tags": []
   },
   "source": [
    "Let's add some buffer to reduce chances that we will see a longer clue in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83951166-17da-4d56-84cb-2a02a2d5b7b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PAD_TO_SIZE = 45"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8ca12f-1c48-48e0-b156-fc11d94def98",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Tensor Building\n",
    "Let's build X and Y tensors for our splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89538fcf-586e-4473-a647-e8e62ece34bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_dataset(split):\n",
    "    splits = {\n",
    "        'train': train,\n",
    "        'dev': dev,\n",
    "        'test': test\n",
    "    }\n",
    "    df = splits[split]\n",
    "    answers_stoi = answers_vocab.get_stoi()\n",
    "    \n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    for clue in df['clue'].values:\n",
    "        indicies = clue_pipeline(clue)\n",
    "        indicies += [PADDING_TOKEN_INDEX] * (PAD_TO_SIZE - len(indicies))\n",
    "        X.append(indicies)\n",
    "\n",
    "    for answer in df['answer'].values:\n",
    "        answer_index = answers_stoi[answer]\n",
    "        Y.append(answer_index)\n",
    "        \n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    return (X, Y)\n",
    "\n",
    "\n",
    "Xdev, Ydev = build_dataset('dev')\n",
    "Xtest, Ytest = build_dataset('test')\n",
    "Xtr, Ytr = build_dataset('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7ba24c7-d4dc-457d-ba2b-a2eccf37b4ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([616288, 45]) torch.Size([616288])\n",
      "torch.Size([77036, 45]) torch.Size([77036])\n",
      "torch.Size([77037, 45]) torch.Size([77037])\n"
     ]
    }
   ],
   "source": [
    "print(Xtr.shape, Ytr.shape)\n",
    "print(Xdev.shape, Ydev.shape)\n",
    "print(Xtest.shape, Ytest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd30014a-e1f6-4190-84c1-f90ec61bd7d8",
   "metadata": {},
   "source": [
    "## Neural Network\n",
    "Let's build a simple network based on the MLP discussed in [this lecture](https://github.com/karpathy/nn-zero-to-hero/blob/master/lectures/makemore/makemore_part2_mlp.ipynb).\n",
    "\n",
    "We will feed the clues into an embedding layer which will provide the inputs to a set of neurons which will output the liklihood of each item in the answers vocabulary being correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f8a1206-66bd-49a0-83a9-3180290037e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "EMBEDDING_DIMENSIONS = 25\n",
    "HIDDEN_NEURON_COUNT = 200\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "g = torch.Generator().manual_seed(42)\n",
    "C = torch.randn((len(clues_vocab), EMBEDDING_DIMENSIONS))\n",
    "W1 = torch.randn(PAD_TO_SIZE * EMBEDDING_DIMENSIONS, HIDDEN_NEURON_COUNT)\n",
    "b1 = torch.randn(HIDDEN_NEURON_COUNT)\n",
    "W2 = torch.randn((HIDDEN_NEURON_COUNT, len(answers_vocab)))\n",
    "b2 = torch.randn(len(answers_vocab))\n",
    "parameters = [C, W1, b1, W2, b2]\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "963ccf94-d172-4f0a-934b-7cb616706f75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14987353"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.nelement() for p in parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a05f83-d970-496c-821a-02f9c81c096a",
   "metadata": {},
   "source": [
    "Let's construct the forward pass and make sure we understand what's happening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3dd78180-9f9c-40e6-80fa-a62b66f66adc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 45, 25])\n",
      "64,45, 25\n",
      "torch.Size([64, 1125])\n",
      "64,1125\n",
      "torch.Size([64, 200])\n",
      "64,200\n",
      "torch.Size([64, 62953])\n",
      "64,62953\n",
      "59.47833251953125\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    # minibatch\n",
    "    ix = torch.randint(0, Xtr.shape[0], (BATCH_SIZE,))\n",
    "    \n",
    "    # forward pass\n",
    "    \n",
    "    # do lookup\n",
    "    emb = C[Xtr[ix]] # (BATCH_SIZE, PAD_TO_SIZE, EMBEDDING_DIMENSIONS)\n",
    "    print(emb.shape)\n",
    "    print(f'{BATCH_SIZE},{PAD_TO_SIZE}, {EMBEDDING_DIMENSIONS}')\n",
    "    \n",
    "    # concat embeddings together\n",
    "    concat = emb.view(-1, PAD_TO_SIZE * EMBEDDING_DIMENSIONS) # (BATCH_SIZE, PAD_TO_SIZE * EMBEDDING_DIMENSIONS)\n",
    "    print(concat.shape)\n",
    "    print(f'{BATCH_SIZE},{PAD_TO_SIZE * EMBEDDING_DIMENSIONS}')\n",
    "    \n",
    "    # hidden layer\n",
    "    h = torch.tanh(concat @ W1 + b1) # (BATCH_SIZE, HIDDEN_NEURON_COUNT)\n",
    "    print(h.shape)\n",
    "    print(f'{BATCH_SIZE},{HIDDEN_NEURON_COUNT}')\n",
    "    \n",
    "    # output layer\n",
    "    logits = h @ W2 + b2 # (BATCH_SIZE, len(answers_vocab))\n",
    "    print(logits.shape)\n",
    "    print(f'{BATCH_SIZE},{len(answers_vocab)}')\n",
    "    \n",
    "    loss = F.cross_entropy(logits, Ytr[ix])\n",
    "    print(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2aac0a-19dd-4f03-b6da-5434aa30e256",
   "metadata": {},
   "source": [
    "Looks good! Loss is high, but we'll fix that ðŸ˜…. Let's start with a simple training cycle to see if what we have works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06fa7483-ea49-44fc-b38e-ea26bca09c3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss: 59.89610290527344\n",
      "Final loss: 31.12291145324707\n",
      "CPU times: user 1min 27s, sys: 12.7 s, total: 1min 40s\n",
      "Wall time: 25.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "LEARNING_RATE = 0.1\n",
    "\n",
    "for i in range(1000):\n",
    "    # minibatch\n",
    "    ix = torch.randint(0, Xtr.shape[0], (BATCH_SIZE,))\n",
    "    \n",
    "    # forward pass\n",
    "    emb = C[Xtr[ix]] # (BATCH_SIZE, PAD_TO_SIZE, EMBEDDING_DIMENSIONS)\n",
    "    concat = emb.view(-1, PAD_TO_SIZE * EMBEDDING_DIMENSIONS) # (BATCH_SIZE, PAD_TO_SIZE * EMBEDDING_DIMENSIONS)\n",
    "    h = torch.tanh(concat @ W1 + b1) # (BATCH_SIZE, HIDDEN_NEURON_COUNT)\n",
    "    logits = h @ W2 + b2 # (BATCH_SIZE, len(answers_vocab))\n",
    "    loss = F.cross_entropy(logits, Ytr[ix])\n",
    "    if i == 0:\n",
    "        print('Initial loss:', loss.item())\n",
    "    \n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "    \n",
    "    # update\n",
    "    for p in parameters:\n",
    "        p.data += -LEARNING_RATE * p.grad\n",
    "\n",
    "print('Final loss:', loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc61838-a20e-4d16-8fe8-3218eb91983e",
   "metadata": {},
   "source": [
    "Seems, to be working! Now let's figure out how to optimize our hyperparameters. The first step is to evaluate our result against the dev set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f4d53efb-973b-4eb4-a76e-06c083479df4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev loss: 29.713613510131836\n",
      "CPU times: user 20.2 s, sys: 9.38 s, total: 29.5 s\n",
      "Wall time: 6.39 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "emb = C[Xdev] # (BATCH_SIZE, PAD_TO_SIZE, EMBEDDING_DIMENSIONS)\n",
    "concat = emb.view(-1, PAD_TO_SIZE * EMBEDDING_DIMENSIONS) # (BATCH_SIZE, PAD_TO_SIZE * EMBEDDING_DIMENSIONS)\n",
    "h = torch.tanh(concat @ W1 + b1) # (BATCH_SIZE, HIDDEN_NEURON_COUNT)\n",
    "logits = h @ W2 + b2 # (BATCH_SIZE, len(answers_vocab))\n",
    "loss = F.cross_entropy(logits, Ydev)\n",
    "\n",
    "print('Dev loss:', loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aae8150-1582-4740-895a-4b91afbae631",
   "metadata": {},
   "source": [
    "We have a solid setup for tuning our hyperparameters - let's learn how to do that in the next notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
